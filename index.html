<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Helping</title>
    <style>
        div{
            padding-top: 100vh;
            
        }

        a{
            color: aquamarine;
            text-decoration: none;
        }
    </style>
</head>
<body>
    <div>

        <strong> Outlier Detection</strong>
        <pre>

            # -*- coding: utf-8 -*-
            import pandas as pd
            
            df = pd.read_csv("../banknote.csv")
            
            df.head()
            
            """# New Section"""
            
            import seaborn as sns
            import matplotlib.pyplot as plt
            sns.boxplot(data=df,x=df["Length"])
            plt.title("Boxplot of Swiss Banknote Length")
            
            def boxplot(column):
                sns.boxplot(data=df,x=df[f"{column}"])
                plt.title(f"Boxplot of Swiss Banknote {column}")
                plt.show()
            
            boxplot('Length')
            boxplot('Right')
            boxplot('Left')
            boxplot('Bottom')
            boxplot('Top')
            boxplot('Diagonal')
            
            

        </pre>
        <strong>Classification KNN</strong>
        <pre>

            import numpy as np
            import pandas as pd
            
            from sklearn.datasets import load_iris
            li = load_iris()
            li
            
            X = pd.DataFrame(li['data'],columns=li['feature_names'])
            print(X.head())
            
            target = pd.DataFrame(li['target'],columns=['iris'])
            y = target['iris']
            y.value_counts()
            
            from sklearn.model_selection import train_test_split
            X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)
            
            from sklearn.neighbors import KNeighborsClassifier
            clf = KNeighborsClassifier(n_neighbors=3)
            clf.fit(X_train,y_train)
            
            y_pred = clf.predict(X_test)
            
            print(clf.score(X_test,y_test))
            
            


        </pre>
        <strong>KNN</strong>
        <pre>

            from sklearn.neighbors import KNeighborsClassifier
            from sklearn.model_selection import train_test_split
            from sklearn.datasets import load_iris
            import pandas as pd
            import numpy as np
            
            irisData = load_iris()
            
            X = pd.DataFrame(data = irisData.data)
            target = pd.DataFrame(irisData['target'],columns=['iris'])
            y = target['iris']
            
            X.head()
            
            y.value_counts()
            
            np.random.seed(5)
            
            from sklearn.model_selection import train_test_split
            X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)
            
            knn = KNeighborsClassifier(n_neighbors=7)
              
            knn.fit(X_train, y_train)
            
            y_pred = knn.predict(X_test)
            
            y_pred
            
            knn.score(X_test,y_test)
            
            
            
            neighbors = np.arange(1, 9)
            train_accuracy = np.empty(len(neighbors))
            test_accuracy = np.empty(len(neighbors))
            
            for i, k in enumerate(neighbors):
                knn = KNeighborsClassifier(n_neighbors=k)
                knn.fit(X_train, y_train)
                  
                # Compute training and test data accuracy
                train_accuracy[i] = knn.score(X_train, y_train)
                test_accuracy[i] = knn.score(X_test, y_test)
            
            import matplotlib.pyplot as plt
            plt.plot(neighbors, test_accuracy, label = 'Testing dataset Accuracy')
            plt.plot(neighbors, train_accuracy, label = 'Training dataset Accuracy')
              
            plt.legend()
            plt.xlabel('n_neighbors')
            plt.ylabel('Accuracy')
            plt.show()
            
            
        </pre>



        <strong>k means</strong>
        <pre>
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

dataset = pd.read_csv('https://raw.githubusercontent.com/mahesh147/KMeans-Clustering/master/Mall_Customers.csv')

dataset.head()

X = dataset.iloc[:,[3,4]].values

from sklearn.cluster import KMeans
wcss =[]
for i in range (1,11):
    kmeans = KMeans(n_clusters = i, init = 'k-means++', max_iter =300, n_init = 10, random_state = 0)
    kmeans.fit(X)
    wcss.append(kmeans.inertia_)

plt.plot(range(1,11),wcss)
plt.title('The Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()

kmeans=KMeans(n_clusters= 5, init = 'k-means++', max_iter = 300, n_init = 10, random_state = 0)
Y_Kmeans = kmeans.fit_predict(X)

plt.scatter(X[Y_Kmeans == 0, 0], X[Y_Kmeans == 0,1],s = 100, c='red', label = 'Cluster 1')

plt.scatter(X[Y_Kmeans == 1, 0], X[Y_Kmeans == 1,1],s = 100, c='blue', label = 'Cluster 2')

plt.scatter(X[Y_Kmeans == 2, 0], X[Y_Kmeans == 2,1],s = 100, c='green', label = 'Cluster 3')

plt.scatter(X[Y_Kmeans == 3, 0], X[Y_Kmeans == 3,1],s = 100, c='cyan', label = 'Cluster 4')

plt.scatter(X[Y_Kmeans == 4, 0], X[Y_Kmeans == 4,1],s = 100, c='magenta', label = 'Cluster 5')

plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], s = 300, c = 'yellow', label = 'Centroids')

plt.title('Clusters of clients')
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending score (1-100)')
plt.legend()
plt.show()


        </pre>
        
        <strong>Collaborative Movie Recommender</strong>
        <pre>
            # -*- coding: utf-8 -*-

            import pandas as pd
            import numpy as np
            
            df = pd.DataFrame({'Divyanshu':[0,3,0,5,0,0,4,5,0,2], 'Tej':[0,0,3,2,5,0,4,0,3,0], 'Tushar':[3,1,0,3,5,0,0,4,0,0], 'Sneha':[4,3,4,2,0,0,0,2,0,0], 
                               'Aasritha':[2,0,0,4,0,4,4,3,5,0], 'Varin':[1,0,2,4,5,0,4,0,5,0], 'Varsneya':[2,0,0,3,0,4,3,3,0,0], 'Ishika':[0,0,0,3,0,2,4,3,4,0], 
                               'Naman':[5,0,0,0,5,3,0,3,0,4], 'Vishal':[1,0,2,0,4,0,4,3,0,0]}, 
                              index=['Avatar','Iron Man','Life of Pi','Avengers','Harry Potter','Memento','Inception','Dragonfly','Shaolin Soccer','Ip man'])
            df
            
            df.values
            
            from sklearn.neighbors import NearestNeighbors
            knn = NearestNeighbors(metric='cosine', algorithm='brute')
            knn.fit(df.values)
            distances, indices = knn.kneighbors(df.values, n_neighbors=3)
            
            indices
            
            distances
            
            for title in df.index:
            
              index_user_likes = df.index.tolist().index(title) # get an index for a movie
              sim_movies = indices[index_user_likes].tolist() # make list for similar movies
              movie_distances = distances[index_user_likes].tolist() # the list for distances of similar movies
              id_movie = sim_movies.index(index_user_likes) # get the position of the movie itself in indices and distances
            
              print('Similar Movies to '+str(df.index[index_user_likes])+':\n')
            
            
              sim_movies.remove(index_user_likes) # remove the movie itself in indices
              movie_distances.pop(id_movie) # remove the movie itself in distances
            
              j = 1
              
              for i in sim_movies:
                print(str(j)+': '+str(df.index[i])+', the distance with '+str(title)+': '+str(movie_distances[j-1]))
                j = j + 1
                  
              print('\n')
            
            
            
            """# Recommend Similar movies to selected movie"""
            
            def recommend_movie(title):
            
              index_user_likes = df.index.tolist().index(title) # get an index for a movie
              sim_movies = indices[index_user_likes].tolist() # make list for similar movies
              movie_distances = distances[index_user_likes].tolist() # the list for distances of similar movies
              id_movie = sim_movies.index(index_user_likes) # get the position of the movie itself in indices and distances
            
              print('Similar Movies to '+str(df.index[index_user_likes])+': \n')
            
              sim_movies.remove(index_user_likes) # remove the movie itself in indices
              movie_distances.pop(id_movie) # remove the movie itself in distances
            
              j = 1
                
              for i in sim_movies:
                print(str(j)+': '+str(df.index[i])+', the distance with '+str(title)+': '+str(movie_distances[j-1]))
                j = j + 1
            
            recommend_movie('Inception')
            
            
            
            """# Recommend Similar movie to selected User"""
            
            knn = NearestNeighbors(metric='cosine', algorithm='brute')
            knn.fit(df.values)
            distances, indices = knn.kneighbors(df.values, n_neighbors=3)
            
            index_for_movie = df.index.tolist().index('Avengers') # it returns 0
            sim_movies = indices[index_for_movie].tolist() # make list for similar movies
            movie_distances = distances[index_for_movie].tolist() # the list for distances of similar movies
            id_movie = sim_movies.index(index_for_movie) # get the position of the movie itself in indices and distances
            sim_movies.remove(index_for_movie) # remove the movie itself in indices
            movie_distances.pop(id_movie) # remove the movie itself in distances
            
            print('The Nearest Movies to Avatar:', sim_movies)
            print('The Distance from Avatar:', movie_distances)
            
            movie_similarity = [-x+1 for x in movie_distances] # inverse distance 
            
            predicted_rating = (movie_similarity[0]*df.iloc[sim_movies[0],7] + movie_similarity[1]*df.iloc[sim_movies[1],7])/sum(movie_similarity)
            print(predicted_rating)
            
            
            
            """# Building a recommender"""
            
            # find the nearest neighbors using NearestNeighbors(n_neighbors=3)
            number_neighbors = 3
            knn = NearestNeighbors(metric='cosine', algorithm='brute')
            knn.fit(df.values)
            distances, indices = knn.kneighbors(df.values, n_neighbors=number_neighbors)
            
            # copy df
            df1 = df.copy()
            
            # convert user_name to user_index
            user_index = df.columns.tolist().index('Divyanshu')
            
            # t: movie_title, m: the row number of t in df
            for m,t in list(enumerate(df.index)):
              
              # find movies without ratings by user_4
              if df.iloc[m, user_index] == 0:
                sim_movies = indices[m].tolist()
                movie_distances = distances[m].tolist()
                
                # Generally, this is the case: indices[3] = [3 6 7]. The movie itself is in the first place.
                # In this case, we take off 3 from the list. Then, indices[3] == [6 7] to have the nearest NEIGHBORS in the list. 
                if m in sim_movies:
                  id_movie = sim_movies.index(m)
                  sim_movies.remove(m)
                  movie_distances.pop(id_movie) 
            
                # However, if the percentage of ratings in the dataset is very low, there are too many 0s in the dataset. 
                # Some movies have all 0 ratings and the movies with all 0s are considered the same movies by NearestNeighbors(). 
                # Then,even the movie itself cannot be included in the indices. 
                # For example, indices[3] = [2 4 7] is possible if movie_2, movie_3, movie_4, and movie_7 have all 0s for their ratings.
                # In that case, we take off the farthest movie in the list. Therefore, 7 is taken off from the list, then indices[3] == [2 4].
                else:
                  sim_movies = sim_movies[:number_neighbors-1]
                  movie_distances = movie_distances[:number_neighbors-1]
                    
                  # movie_similarty = 1 - movie_distance    
                movie_similarity = [1-x for x in movie_distances]
                movie_similarity_copy = movie_similarity.copy()
                nominator = 0
            
                # for each similar movie
                for s in range(0, len(movie_similarity)):
                  
                  # check if the rating of a similar movie is zero
                  if df.iloc[sim_movies[s], user_index] == 0:
            
                    # if the rating is zero, ignore the rating and the similarity in calculating the predicted rating
                    if len(movie_similarity_copy) == (number_neighbors - 1):
                      movie_similarity_copy.pop(s)
                      
                    else:
                      movie_similarity_copy.pop(s-(len(movie_similarity)-len(movie_similarity_copy)))
            
                  # if the rating is not zero, use the rating and similarity in the calculation
                  else:
                    nominator = nominator + movie_similarity[s]*df.iloc[sim_movies[s],user_index]
            
                # check if the number of the ratings with non-zero is positive
                if len(movie_similarity_copy) > 0:
                  
                  # check if the sum of the ratings of the similar movies is positive.
                  if sum(movie_similarity_copy) > 0:
                    predicted_r = nominator/sum(movie_similarity_copy)
            
                  # Even if there are some movies for which the ratings are positive, some movies have zero similarity even though they are selected as similar movies.
                  # in this case, the predicted rating becomes zero as well  
                  else:
                    predicted_r = 0
                # if all the ratings of the similar movies are zero, then predicted rating should be zero
                else:
                  predicted_r = 0
            
              # place the predicted rating into the copy of the original dataset
                df1.iloc[m,user_index] = predicted_r
            
            def recommend_movies(user, num_recommended_movies):
            
              print('The list of the Movies {} Has Watched \n'.format(user))
            
              for m in df[df[user] > 0][user].index.tolist():
                print(m)
              
              print('\n')
            
              recommended_movies = []
            
              for m in df[df[user] == 0].index.tolist():
            
                index_df = df.index.tolist().index(m)
                predicted_rating = df1.iloc[index_df, df1.columns.tolist().index(user)]
                recommended_movies.append((m, predicted_rating))
            
              sorted_rm = sorted(recommended_movies, key=lambda x:x[1], reverse=True)
              
              print('The list of the Recommended Movies \n')
              rank = 1
              for recommended_movie in sorted_rm[:num_recommended_movies]:
                
                print('{}: {} - predicted rating:{}'.format(rank, recommended_movie[0], recommended_movie[1]))
                rank = rank + 1
            
            recommend_movies('Divyanshu',5)
            
            df1 = df.copy()
            
            def movie_recommender(user, num_neighbors, num_recommendation):
              
              number_neighbors = num_neighbors
            
              knn = NearestNeighbors(metric='cosine', algorithm='brute')
              knn.fit(df.values)
              distances, indices = knn.kneighbors(df.values, n_neighbors=number_neighbors)
            
              user_index = df.columns.tolist().index(user)
            
              for m,t in list(enumerate(df.index)):
                if df.iloc[m, user_index] == 0:
                  sim_movies = indices[m].tolist()
                  movie_distances = distances[m].tolist()
                
                  if m in sim_movies:
                    id_movie = sim_movies.index(m)
                    sim_movies.remove(m)
                    movie_distances.pop(id_movie) 
            
                  else:
                    sim_movies = sim_movies[:num_neighbors-1]
                    movie_distances = movie_distances[:num_neighbors-1]
                       
                  movie_similarity = [1-x for x in movie_distances]
                  movie_similarity_copy = movie_similarity.copy()
                  nominator = 0
            
                  for s in range(0, len(movie_similarity)):
                    if df.iloc[sim_movies[s], user_index] == 0:
                      if len(movie_similarity_copy) == (number_neighbors - 1):
                        movie_similarity_copy.pop(s)
                      else:
                        movie_similarity_copy.pop(s-(len(movie_similarity)-len(movie_similarity_copy)))
                        
                    else:
                      nominator = nominator + movie_similarity[s]*df.iloc[sim_movies[s],user_index]
                      
                  if len(movie_similarity_copy) > 0:
                    if sum(movie_similarity_copy) > 0:
                      predicted_r = nominator/sum(movie_similarity_copy)
                    
                    else:
                      predicted_r = 0
            
                  else:
                    predicted_r = 0
                    
                  df1.iloc[m,user_index] = predicted_r
              recommend_movies(user,num_recommendation)
            
            movie_recommender('Divyanshu', 4, 5)
            
            




        </pre>
        <a href="./public/resources/ANN.pdf">ANN sem 6</a>
        <li>
            <a href="https://drive.google.com/drive/folders/1dwxWAWVA6O-Nct4N23eAfmAQlL0NHUGo">Tej</a>
        </li>
        <a href="./tuhsar_notes.html">Tushar Notes</a>
    
        
        <pre>
        #include <stdio.h>
#include <string.h>
#include <stdlib.h>
#include <errno.h>
#include <string.h>
#include <sys/types.h>
#include <sys/ipc.h>
#include <sys/msg.h>

#define PERMS 0644
struct my_msgbuf {
   long mtype;
   char mtext[200];
};

int main(void) {
   struct my_msgbuf buf;
   int msqid;
   int len;
   key_t key;
   system("touch msgq.txt");
   
   if ((key = ftok("msgq.txt", 'B')) == -1) {
      perror("ftok");
      exit(1);
   }
   
   if ((msqid = msgget(key, PERMS | IPC_CREAT)) == -1) {
      perror("msgget");
      exit(1);
   }
   printf("message queue: ready to send messages.\n");
   printf("Enter lines of text, ^D to quit:\n");
   buf.mtype = 1; /* we don't really care in this case */
   int sum=100;
   
   while(sum>10) {

    int arr[10];
    pritnf("Enter Numbers in the array \n");
    for(int i=0; i<10; i++){
        printf("%d: ", i+1);
        scanf("%d",&arr[i]);
        printf("\n");
    }
    int sum=0;
    for(int i=0; i<10; i++){
        sum+=arr[i];
    }

    sum/=10;
    printf("Sum divided by 10: \"%d\" ",sum);
    if(sum<10)
    {
        printf("Less than 10, stopping the communication\n");
        break;
    }
      len = strlen(buf.mtext);
      /* remove newline at end, if it exists */
      if (buf.mtext[len-1] == '\n') buf.mtext[len-1] = '\0';
      if (msgsnd(msqid, &buf, len+1, 0) == -1) /* +1 for '\0' */
      perror("msgsnd");
   }
   strcpy(buf.mtext, "end");
   len = strlen(buf.mtext);
   if (msgsnd(msqid, &buf, len+1, 0) == -1) /* +1 for '\0' */
   perror("msgsnd");
   
   if (msgctl(msqid, IPC_RMID, NULL) == -1) {
      perror("msgctl");
      exit(1);
   }
   printf("message queue: done sending messages.\n");
   return 0;
}
        </pre>
        
        #include <stdio.h>
#include <stdlib.h>
#include <errno.h>
#include <sys/types.h>
#include <sys/ipc.h>
#include <sys/msg.h>
#include<string.h>

#define PERMS 0644
struct my_msgbuf {
   long mtype;
   char mtext[200];
};

int main(void) {
   struct my_msgbuf buf;
   int msqid;
   int toend;
   key_t key;
   
   if ((key = ftok("msgq.txt", 'B')) == -1) {
      perror("ftok");
      exit(1);
   }
   
   if ((msqid = msgget(key, PERMS)) == -1) { /* connect to the queue */
      perror("msgget");
      exit(1);
   }
   printf("message queue: ready to receive messages.\n");
   
   for(;;) { /* normally receiving never ends but just to make conclusion 
             /* this program ends wuth string of end */
      if (msgrcv(msqid, &buf, sizeof(buf.mtext), 0, 0) == -1) {
         perror("msgrcv");
         exit(1);
      }
      printf("recvd: \"%s\"\n", buf.mtext);
      toend = strcmp(buf.mtext,"end");
      if (toend == 0)
      break;
   }
   printf("message queue: done receiving messages.\n");
   system("rm msgq.txt");
   return 0;
}
        
        
        <pre>
        
        
        
        
        
        </pre>
        
<strong>HEBB</strong>
<pre>
print("\n")
def printable(x1,x2,bias,y):
    print("\t\tAND GATE logic Table")
    print("__________________________________________________________")
    print("| ","X1","\t|\t ","X2","\t|\t ","b","\t |\t","Y \t|")
    print("________________________________________________________")
    for i in range(4):
        print("| ",x1[i],"\t|\t ",x2[i],"\t|\t ",bias[i],"\t |\t",y[i],"\t|")
        print("________________________________________________________")

x1=[1,-1,1,-1]
x2=[1,1,-1,-1]
bias=[1,1,1,1]
y=[1,-1,-1,-1]

printable(x1,x2,bias,y)
w1=0
w2=0
b=0

print("\n\n")
print("\t\t\t\t HEBB LEARNING RULE TABLE")
print()
print("| ","X1","\t|\t ","X2","\t|\t ","bias","\t |\t","Y \t|","w1","\t|\t ","w2","\t|\t ","b","\t|\t ")
print("_________________________________________________________________________________________________________________")
for i in range(4):
    w1 = w1 + x1[i]*y[i]
    w2= w2+ x2[i]*y[i]

    b=b+y[i]

    print("| ",x1[i],"\t|\t ",x2[i],"\t|\t ",bias[i],"\t |\t",y[i],"\t|",w1,"\t|\t ",w2,"\t|\t ",b,"\t|\t ")
    print("__________________________________________________________________________________________________________________")


</pre>

<hr>
<br>

<strong>MCP OR</strong>
<pre>
    class MpNeuron:
  inpOuts = []

  def addinpOuput(self, inp, out):
    self.inpOuts.append([inp, out])

  def getNetinp(self, inp, weights):
    netinp = 0
    for i in range(len(inp)):
      netinp += inp[i] * weights[i]
    return netinp

  def getValidThreshold(self, weights):
    threshold = 10000000

    for inp, out in self.inpOuts:
      if out == 1:
        threshold = min(threshold, self.getNetinp(inp, weights))

    for inp, out in self.inpOuts:
      if out == 0 and threshold <= self.getNetinp(inp, weights):
        return None

    return threshold


orNeuron = MpNeuron()
orNeuron.addinpOuput([0, 0], 0)
orNeuron.addinpOuput([0, 1], 1)
orNeuron.addinpOuput([1, 0], 1)
orNeuron.addinpOuput([1, 1], 1)

print('Or Gate\'s Truth Table: ')
print('x1 x2 y')
print('-------')
print('0  0  0')
print('0  1  1')
print('1  0  1')
print('1  1  1')
print()

while True:
  weights = list(map(int, input('Enter weights: ').split(' ')))
  threshold = orNeuron.getValidThreshold(weights)

  if threshold != None:
    print('Weights are correct, Threshold Found:', threshold)
    print('Hence, and gate can be realised using mp neuron')
    break
  else:
    print('Invalid weights')
    print()

</pre>
        
<hr>
<br>

<strong>MCP XOR</strong>
<pre>

    def f(yin,theta):
    if yin >= theta: 
        return 1
    else:
        return 0

def makeGate(gateName,first,op,second,x1Header,x2Header,yHeader,yinHeader,w1,w2,theta):
    print()
    print(gateName," gate => ",yHeader," = ",first,op,second)
    
    print("We take w1 = ",w1," and w2 = ",w2)
    print()
    
    x1 = [1,1,0,0]
    x2 = [1,0,1,0]
    y = []
    
    # calculate y
    for i in range(0,4):
        if first[0] != "~" and second[0] != "~" and op == "|":
            ans = x1[i] | x2[i]
            
        elif first[0] != "~" and second[0] != "~" and op == "&":
            ans = x1[i] & x2[i]
            
        elif first[0] != "~" and second[0] == "~" and op == "|":
            ans = x1[i] | ~x2[i]
            
        elif first[0] != "~" and second[0] == "~" and op == "&":
            ans = x1[i] & ~x2[i]
            
        elif first[0] == "~" and second[0] != "~" and op == "|":
            ans = ~x1[i] | x2[i]
            
        elif first[0] == "~" and second[0] != "~" and op == "&":
            ans = ~x1[i] & x2[i]
            
        elif first[0] == "~" and second[0] == "~" and op == "|":
            ans = ~x1[i] | ~x2[i]
            
        elif first[0] == "~" and second[0] == "~" and op == "&":
            ans = ~x1[i] & ~x2[i]
            
        y.append(ans)
        
    
    yin = []
    for i in range(0,4):
        ans = w1*x1[i] + w2*x2[i]
        yin.append(ans)
    
    print(x1Header,"       ",x2Header,"       ",yHeader,"       ",yinHeader)
        
    for i in range(0,4):
        print(x1[i],"        ",x2[i],"        ",y[i],"         ",yin[i])
            
            
    print()
    print("And setting theta = ",theta)
    
    
    
    print()
    print(yHeader,"  =  f(",yinHeader,") = { ",f(theta,theta),"   ",yinHeader," >= ", theta)
    print("                   { " ,f(theta-1,theta),"   ",yinHeader," < ", theta)
    
    # line
    print()
    print("*****************************************")
    

makeGate("ANDNOT","x1","&","~x2","x1","x2","z1","z1in",1,-1,1)
makeGate("ANDNOT","~x1","&","x2","x1","x2","z2","z2in",-1,1,1)
makeGate("OR","z1","|","z2","z1","z2","y","yin",1,1,1)

print("So XOR gate can be realised by using MCP model")
</pre>
<hr>
<br>

<strong>Perceptron AND</strong>
<pre>
    import numpy as np

def sigmoid(x):
  return 1/(1+np.exp(-x))

def activation_sigmoid(x):
  y = sigmoid(x)
  if y>0:
    return 1
  elif y==0:
    return 0
  else:
    return -1

def step_function(y):
  if y>0:
    return 1
  elif y==0:
    return 0
  else:
    return -1

w = [0,0]
Wold=[0,0]
b = 0
alpha = 1

x1 = [1,1,-1,-1]
x2 = [1,-1,1,-1]
t = [1,-1,-1,-1]
epoch=True
num=1
while(epoch):
  print("\n Epoch", num ," : ")
  num=num+1
  print("_______________________________________")
  for i in range(4):
    yin = x1[i]*w[0]+x2[i]*w[1]+b
    y = step_function(yin)
    print(y)
    if(y!=t[i]):
      w[0] = w[0] + alpha*t[i]*x1[i]
      w[1] = w[1] + alpha*t[i]*x2[i]
      b = b + alpha*t[i]
      
    print(f'Weights : w1 = {w[0]} , w2 = {w[1]} , b = {b}')
  if(Wold[0]==w[0] and Wold[1]==w[1]):
      epoch=0
  Wold=w

print(f'Weights : w1 = {w[0]} , w2 = {w[1]} , b = {b}')
</pre>
<hr>
<br>

<strong>Adaline OR</strong>
<pre>
    import numpy as np

features = np.array(
    [
        [-1, -1],
        [-1, 1],
        [1, -1],
        [1, 1]
    ])

labels = np.array([-1, 1, 1, 1])

print(features, labels)

weight = [0, 0]
bias = 1
learning_rate = 0.2
epoch = 10

for i in range(epoch):

    print("epoch :", i+1)

    sum_squared_error = 0.0

    for j in range(features.shape[0]):

        actual = labels[j]

        x1 = features[j][0]
        x2 = features[j][1]

        unit = (x1 * weight[0]) + (x2 * weight[1]) + bias

        error = actual - unit

        print("error =", error)

        sum_squared_error += error * error

        weight[0] += learning_rate * error * x1
        weight[1] += learning_rate * error * x2

        bias += learning_rate * error

    print("sum of squared error = ", sum_squared_error/4, "\n\n")

</pre>
<hr>
<br>

<strong>Adaline AND</strong>
<pre>
    import numpy as np

features = np.array(
    [
        [-1, -1],
        [-1, 1],
        [1, -1],
        [1, 1]
    ])

labels = np.array([-1, -1, -1, 1])

print(features, labels)

weight = [0, 0]
bias = 1
learning_rate = 0.2
epoch = 10

for i in range(epoch):

    print("epoch :", i+1)

    sum_squared_error = 0.0

    for j in range(features.shape[0]):

        actual = labels[j]

        x1 = features[j][0]
        x2 = features[j][1]

        unit = (x1 * weight[0]) + (x2 * weight[1]) + bias

        error = actual - unit

        print("error =", error)

        sum_squared_error += error * error

        weight[0] += learning_rate * error * x1
        weight[1] += learning_rate * error * x2

        bias += learning_rate * error

    print("sum of squared error = ", sum_squared_error/4, "\n\n")

</pre>
<hr>
<br>

<strong>Perceptron Tars ANDNOT</strong>
<pre>
    def activation(yin,theta):
    if yin>0:
        return 1
    elif yin &lt; 0:
        return -1
    else:
        return 0

x1 = [1, 1, -1, -1]
x2 = [1, -1, 1, -1]
t = [-1,1,-1,-1]
bias, w1,w2=0,0,0
alpha, theta=1, 0
numEpoch = int(input("Enter number of epochs: "))

for i in range(numEpoch):
    nowtchange =True
    print("For Epoch:", i + 1)
    for j in range(4):
        sum = 0
        sum = sum + x1[j]*w1 + x2[j]*w2
        yin = bias+sum
        y = activation(yin,theta)
        if t[j] != y:
            nowtchange = False
            w1 = w1 + alpha*t[j]*x1[j]
            w2 = w2 + alpha*t[j]*x2[j]
            bias = bias + alpha*t[j]
            print("Updated Weights are")
            print(f'w1: {w1}, w2: {w2}, b: {bias}')
        else:
            print("No change in Weights")
            print(f'w1: {w1}, w2: {w2}, b: {bias}')
    if nowtchange:
        print("***********************No weight change in entire epoch***************************")

        break




</pre>

<strong>Perceptron ANDNOT</strong>
<pre>
    def activationFn(x, theta):
    if x < -theta:
      return -1
    if -theta <= x <= theta:
      return 0
    return 1
  
  
  class Perceptron:
    def __init__(self, N, theta=0, alpha=1):
      self.N = N
      self.weights = [0] * N
      self.bias = 0
      self.theta = theta
      self.alpha = alpha
      self.expectedInOuts = []
  
    def addexpectedInOut(self, inp, out):
      self.expectedInOuts.append([inp, out])
  
    def getNetinp(self, inp):
      netinp = self.bias
      for i in range(len(inp)):
        netinp += inp[i] * self.weights[i]
      return netinp
  
    def getNetOut(self, inp):
      return activationFn(self.getNetinp(inp), self.theta)
  
    # eg - x1 x2 1  t  yin  y 	dw1 dw2 db	w1 w2 b
    def printLine(self, x, t, yin, y, dw, db, w, b):
      def formattedStr(str): return '{:>4}'.format(str)
  
      s = ''
      for val in x:
        s += formattedStr(val)
      s += formattedStr(1)
      s += '  |  '
      s += formattedStr(t)
      s += '  |  '
      s += formattedStr(yin)
      s += '  |  '
      s += formattedStr(y)
      s += '  |  '
      for val in dw:
        s += formattedStr(val)
      s += formattedStr(db)
      s += '  |  '
      for val in w:
        s += formattedStr(val)
      s += formattedStr(b)
  
      print(s)
  
    def train(self):
      changed = True
      epoch = 1
  
      self.printLine(
          ['x{}'.format(i) for i in range(1, self.N + 1)],
          't',
          'yin',
          'y',
          ['dw{}'.format(i) for i in range(1, self.N + 1)],
          'db',
          ['w{}'.format(i) for i in range(1, self.N + 1)],
          'b'
      )
  
      while changed:
        changed = False
        print('EPOCH -', epoch)
  
        for x, t in self.expectedInOuts:
          yin = self.getNetinp(x)
          y = self.getNetOut(x)
          dw = [0] * self.N
          db = 0
          if y != t:
            for i in range(self.N):
              dw[i] = self.alpha * t * x[i]
              self.weights[i] += dw[i]
            db = self.alpha * t
            self.bias += db
            changed = True
  
          self.printLine(x, t, yin, y, dw, db, self.weights, self.bias)
  
        epoch += 1
  
    def test(self, inp):
      return self.getNetOut(inp)
  
  
  andNot = Perceptron(2, theta=0, alpha=1)
  andNot.addexpectedInOut([1, 1], -1)
  andNot.addexpectedInOut([1, -1], 1)
  andNot.addexpectedInOut([-1, 1], -1)
  andNot.addexpectedInOut([-1, -1], -1)
  
  andNot.train()
  print(andNot.weights, andNot.bias)
  
</pre>
<hr>
<br>

<strong>Auto Associative</strong>
<pre>
    from numpy import size

#activation function
def f(yinj):
    if yinj > 0:
        return 1
    else:
        return -1

print("Auto Associative Networks::")

t = int(input("Enter number of input samples: "))
n = int(input("Enter the number of nodes: "))

X = []
for i in range(t):          # A for loop for row entries
    a = list(map(int, input().split()))
    X.append(a)

Y = X

print("Input Vector is")
for i in range(len(X)):
    print(X[i])
print("\n____________________________\n")
print("Output Vector is")
for i in range(len(Y)):
    print(Y[i])

weights = [[0 for _ in range(n)] for _ in range(n)]

# Training Phase
for k in range(t):
    for i in range(n):
        for j in range(n):
            weights[i][j] += X[k][i]*Y[k][j]


print("\n____________________________\n")
print("Weights after Training:")
for i in range(len(weights)):
    print(weights[i])


while(1):
    print("Enter the testing vector: ")
    # Testing Phase
    test = list(map(int, input().split()))

    print("Test Input", test)

    outs = []
    for j in range(n):
        yinj = 0
        for i in range(n):
            yinj += test[i]*weights[i][j]
        yin = f(yinj)
        outs.append(yin)

    print("Testing Output", outs)
    print("\n")


    AUTO ASSOICATVE 
    2
    4
    1 1 -1 1
    1 -1 -1 -1
</pre>


<hr>
<br>

<strong>Heteroassociative</strong>
<pre>
    print("Heteroassociative Networks::")


def f(yinj):
    if yinj > 0:
        return 1
    if yinj == 0:
        return 0
    else:
        return -1


t = int(input("Enter number of input samples: "))
n = int(input("Enter the number of features: "))
n2 = int(input("Enter length of output: "))
X = []
Y = []
for i in range(t):          # A for loop for row entries
    print("input")
    a = list(map(int, input().split()))
    print("output")
    b = list(map(int, input().split()))
    X.append(a)
    Y.append(b)


print("Input Vector is")
for i in range(len(X)):
    print(X[i])
print("\n____________________________\n")
print("Output Vector is")
for i in range(len(Y)):
    print(Y[i])

weights = [[0 for _ in range(n2)] for _ in range(n)]

# Training Phase
for k in range(t):
    for i in range(n):
        for j in range(n2):
            weights[i][j] += X[k][i]*Y[k][j]

print("\n____________________________\n")
print("Weights after Training:")
for i in range(len(weights)):
    print(weights[i])



# Testing Phase
num = int(input("Enter number of test cases: "))
for p in range(num):
    print("Enter the testing vector: ")

    test = list(map(int, input().split()))
    print("Test Input", test)
    outs = []
    for j in range(n2):
        yinj = 0
        for i in range(n):
            yinj += test[i]*weights[i][j]
        yin = f(yinj)
        outs.append(yin)

    print("Testing Output", outs)
    
    
    HETERO ASSOCIATIVE 
    2
    4
    2
    1 1 1 1
    1 -1
    1 -1 1 -1
    -1 1
</pre>

<hr>
<br>

<strong>BAM</strong>
<pre>
    # Import Python Libraries
import numpy as np

# Take two sets of patterns:
# Set A: Input Pattern
# make 6*1 matrix of inputs
x1 = np.array([1, -1,-1,-1]).reshape(1, 4)
x2 = np.array([1,-1,-1,1]).reshape(1, 4)
x3 = np.array([-1,1,-1,-1]).reshape(1, 4)
x4 = np.array([-1,1,1,-1]).reshape(1, 4)

# Set B: Target Pattern
y1 = np.array([1,-1]).reshape(1,2)
y2 = np.array([1,-1]).reshape(1,2)
y3 = np.array([-1, 1]).reshape(1,2)
y4 = np.array([-1, 1]).reshape(1,2)


print("Set A: Input Pattern, Set B: Target Pattern")
print("\nThe input for pattern 1 is")
print(x1)
print("\nThe target for pattern 1 is")
print(y1)
print("\nThe input for pattern 2 is")
print(x2)
print("\nThe target for pattern 2 is")
print(y2)
print("\nThe input for pattern 3 is")
print(x3)
print("\nThe target for pattern 3 is")
print(y3)
print("\nThe input for pattern 4 is")
print(x4)
print("\nThe target for pattern 4 is")
print(y4)

print("\n------------------------------")

# Calculate weight Matrix: W
inputSet = np.concatenate((x1, x2, x3, x4), axis=0)
targetSet = np.concatenate((y1, y2, y3, y4), axis=0)
print("\nWeight matrix:")
weight = np.dot(inputSet.T, targetSet)
print(weight)

print("\n------------------------------")

# Testing Phase
# Test for Input Patterns: Set A
print("\nTesting for input patterns: Set A")


def testInputs(x, weight):

    # Multiply the input pattern with the weight matrix
    # (weight.T X x)
    y = np.dot(x, weight)
    y[y < 0] = -1
    y[y >= 0] = 1
    return np.array(y)


print("\nOutput of input pattern 1")
print(testInputs(x1, weight))
print("\nOutput of input pattern 2")
print(testInputs(x2, weight))
print("\nOutput of input pattern 3")
print(testInputs(x3, weight))
print("\nOutput of input pattern 4")
print(testInputs(x4, weight))

# Test for Target Patterns: Set B
print("\nTesting for target patterns: Set B")


def testTargets(y, weight):

    # Multiply the target pattern with the weight matrix
    # (weight X y)
    x = np.dot(y, weight.T)
    x[x <= 0] = -1
    x[x > 0] = 1
    return np.array(x)


print("\nOutput of target pattern 1")
print(testTargets(y1, weight))
print("\nOutput of target pattern 2")
print(testTargets(y2, weight))
print("\nOutput of target pattern 3")
print(testTargets(y3, weight))
print("\nOutput of target pattern 4")
print(testTargets(y4, weight))

</pre>
<hr>
<br>

<strong>Hopiefied(Tej)</strong>
<pre>
import numpy as np 
print("Input Vector: [1,1,1,-1]") 
ipvector1 = np.array([1,1,1,1,1]).reshape(1,5) 
ipvector2 = np.array([1,-1,-1,1,-1]).reshape(1,5) 
ipvector3 = np.array([-1,1,-1,-1,-1]).reshape(1,5) 

def activation(x): 
    if(x>0): return 1
    else: return 0
w1=np.transpose(ipvector1)*ipvector1
w2=np.transpose(ipvector2)*ipvector2
w3=np.transpose(ipvector3)*ipvector3

w=w1+w2+w3

for i in range(4): 
    for j in range(4): 
        if(i==j): 
            w[i][j]=0 
print("\n Weight Matrix: ")
print(w) 
#converting to binary
ipvector1 = np.array([1,1,1,1,1])
ipvector2 = np.array([1,0,0,1,0])
ipvector3 = np.array([0,1,0,0,0])
# print("Input vector in binary representation: ",ipvector) 
x=np.array([1,1,1,0,1]).reshape(1,5) 
y=x
for i in range(5): 
    yin = x[0][i] + np.dot(y,w[:,i]) 
    print("yin_",i+1,": ",yin) 
    y[0][i]=activation(yin) 
    print("Updated Y :",y) 
    if((y==ipvector1).all()): 
        print("Hence y=input vector x, vector converge") 
        break
    if((y==ipvector2).all()): 
        print("Hence y=input vector x, vector converge") 
        break
    if((y==ipvector3).all()): 
        print("Hence y=input vector x, vector converge") 
        break
</pre>
<hr>
<br>
<strong>Hopiefied (plot)</strong>
<pre>
    
import matplotlib.pyplot as plt
import numpy as np

nb_patterns = 4   # Number of patterns to learn
pattern_width = 5
pattern_height = 5
max_iterations = 10

# Define Patterns
patterns = np.array([
    [1, -1, -1, -1, 1, 1, -1, 1, 1, -1, 1, -1, 1, 1, -1,
        1, -1, 1, 1, -1, 1, -1, -1, -1, 1.],   # Letter D
    [-1, -1, -1, -1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, - \
     1, 1, 1, -1, 1, -1, -1, -1, 1, 1.],    # Letter J
    [1, -1, -1, -1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, - \
     1, 1, 1, 1, 1, 1, -1, -1, -1, -1.],     # Letter C
    [-1, 1, 1, 1, -1, -1, -1, 1, -1, -1, -1, 1, -1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1.], ],  # Letter M
    dtype=np.float)
fig, ax = plt.subplots(1, nb_patterns, figsize=(15, 10))

for i in range(nb_patterns):
    ax[i].matshow(patterns[i].reshape(
        (pattern_height, pattern_width)), cmap='gray')
    ax[i].set_xticks([])
    ax[i].set_yticks([])
W = np.zeros((pattern_width * pattern_height, pattern_width * pattern_height))

for i in range(pattern_width * pattern_height):
    for j in range(pattern_width * pattern_height):
        if i == j or W[i, j] != 0.0:
            continue

        w = 0.0

        for n in range(nb_patterns):
            w += patterns[n, i] * patterns[n, j]

        W[i, j] = w / patterns.shape[0]
        W[j, i] = W[i, j]
S = np.array([1, -1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, -1.],
             dtype=np.float)

# Show the corrupted pattern
fig, ax = plt.subplots()
ax.matshow(S.reshape((pattern_height, pattern_width)), cmap='gray')
h = np.zeros((pattern_width * pattern_height))
# Defining Hamming Distance matrix for seeing convergence
hamming_distance = np.zeros((max_iterations, nb_patterns))
for iteration in range(max_iterations):
    for i in range(pattern_width * pattern_height):
        i = np.random.randint(pattern_width * pattern_height)
        h[i] = 0
        for j in range(pattern_width * pattern_height):
            h[i] += W[i, j]*S[j]
        S = np.where(h < 0, -1, 1)
    for i in range(nb_patterns):
        hamming_distance[iteration, i] = ((patterns - S)[i] != 0).sum()

    fig, ax = plt.subplots()
    ax.matshow(S.reshape((pattern_height, pattern_width)), cmap='gray')
plt.show()
hamming_distance

</pre>

<hr>
<br>
<strong>Self Organising Maps</strong>
<pre>
    
import matplotlib.pyplot as plt
import numpy as np

nb_patterns = 4   # Number of patterns to learn
pattern_width = 5
pattern_height = 5
max_iterations = 10

# Define Patterns
patterns = np.array([
    [1, -1, -1, -1, 1, 1, -1, 1, 1, -1, 1, -1, 1, 1, -1,
        1, -1, 1, 1, -1, 1, -1, -1, -1, 1.],   # Letter D
    [-1, -1, -1, -1, -1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, - \
     1, 1, 1, -1, 1, -1, -1, -1, 1, 1.],    # Letter J
    [1, -1, -1, -1, -1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, - \
     1, 1, 1, 1, 1, 1, -1, -1, -1, -1.],     # Letter C
    [-1, 1, 1, 1, -1, -1, -1, 1, -1, -1, -1, 1, -1, 1, -1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1.], ],  # Letter M
    dtype=np.float)
fig, ax = plt.subplots(1, nb_patterns, figsize=(15, 10))

for i in range(nb_patterns):
    ax[i].matshow(patterns[i].reshape(
        (pattern_height, pattern_width)), cmap='gray')
    ax[i].set_xticks([])
    ax[i].set_yticks([])
W = np.zeros((pattern_width * pattern_height, pattern_width * pattern_height))

for i in range(pattern_width * pattern_height):
    for j in range(pattern_width * pattern_height):
        if i == j or W[i, j] != 0.0:
            continue

        w = 0.0

        for n in range(nb_patterns):
            w += patterns[n, i] * patterns[n, j]

        W[i, j] = w / patterns.shape[0]
        W[j, i] = W[i, j]
S = np.array([1, -1, -1, -1, -1, 1, 1, 1, 1, 1, -1, 1, 1, 1, 1, -1, 1, 1, 1, 1, 1, 1, -1, -1, -1.],
             dtype=np.float)

# Show the corrupted pattern
fig, ax = plt.subplots()
ax.matshow(S.reshape((pattern_height, pattern_width)), cmap='gray')
h = np.zeros((pattern_width * pattern_height))
# Defining Hamming Distance matrix for seeing convergence
hamming_distance = np.zeros((max_iterations, nb_patterns))
for iteration in range(max_iterations):
    for i in range(pattern_width * pattern_height):
        i = np.random.randint(pattern_width * pattern_height)
        h[i] = 0
        for j in range(pattern_width * pattern_height):
            h[i] += W[i, j]*S[j]
        S = np.where(h < 0, -1, 1)
    for i in range(nb_patterns):
        hamming_distance[iteration, i] = ((patterns - S)[i] != 0).sum()

    fig, ax = plt.subplots()
    ax.matshow(S.reshape((pattern_height, pattern_width)), cmap='gray')
plt.show()
hamming_distance

</pre>

<hr>
<br>

<strong>SOM video</strong>
<pre>
    #Self organizing map clustering algorithm
# The Academician
import numpy as np, numpy.random
from scipy.spatial import distance
np.set_printoptions(suppress=True) #Force-suppress all exponential notation

k = 2
p = 0
alpha = 0.7 # Initial learning rate

X = np.array([
        [1,1,0,0], 
        [0,1,0,0], 
        [0,0,1,0], 
        [0,0,1,1]])


# Print the number of data and dimension 
n = len(X)
d = len(X[0])
addZeros = np.zeros((n, 1))
X = np.append(X, addZeros, axis=1)
print("The SOM algorithm: \n")
print("The training data: \n", X)
print("\nTotal number of data: ",n)
print("Total number of features: ",d)
print("Total number of Clusters: ",k)

C = np.zeros((k,d+1))

weight = np.random.rand(n,k)
print("\nThe initial weight: \n", np.round(weight,2))

for it in range(100): # Total number of iterations
    for i in range(n):
        distMin = 99999999
        for j in range(k):
            dist = np.square(distance.euclidean(weight[:,j], X[i,0:d]))
            if distMin>dist:
                distMin = dist
                jMin = j
        weight[:,jMin] = weight[:,jMin]*(1-alpha) + alpha*X[i,0:d]   
    alpha = 0.5*alpha
    
print("\nThe final weight: \n",np.round(weight,4))

for i in range(n):    
    cNumber = np.where(weight[i] == np.amax(weight[i]))
    X[i,d] = cNumber[0]
    
print("\nThe data with cluster number: \n", X)


    
</pre>
    </div>
</body>
</html>
